<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: devops | Confessions of a Wall Street Programmer]]></title>
  <link href="http://btorpey.github.io/blog/categories/devops/atom.xml" rel="self"/>
  <link href="http://btorpey.github.io/"/>
  <updated>2021-03-19T13:21:09-04:00</updated>
  <id>http://btorpey.github.io/</id>
  <author>
    <name><![CDATA[Bill Torpey]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Custom-Tailored Configuration]]></title>
    <link href="http://btorpey.github.io/blog/2016/10/13/custom-tailor/"/>
    <updated>2016-10-13T00:00:00-04:00</updated>
    <id>http://btorpey.github.io/blog/2016/10/13/custom-tailor</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/customtailor.jpg">

As developers, we seem to take a special delight in personalizing the virtual worlds in which we work -- from color palettes to keyboards, fonts, macros, you name it.  "Off-the-rack" is never good enough, we want Saville Row tailoring for our environments.

And a lot of the tools we use support and encourage that customization, giving us control over every little option.

But not every tool we use does so -- read on to learn a very simple trick to how to take control even when your tool doesn't make that easy.

<!-- more -->

In Linux, we have a couple of common ways to customize the way our tools work -- by defining environment variables, and by using configuration files.  Sometimes these two mechanisms work well together, and we can include environment variables in configuration files to make them flexible in different situations.

Not every tool can expand environment varaiables in its configuration files, however.  In that case, you can use this simple Perl one-liner to subsitute values from the environment into any plain-text file.

    perl -pe '$_=qx"/bin/echo -n \"$_\"";' < sample.ini


What's happpening here is

The `-p` switch tells Perl to read every line of input and print it.

The `-e` switch tells Perl to execute the supplied Perl code against every line of input.

The code snippet replaces the value of the input line (`$_`) with the results of the shell command specified by the `qx` function.  That shell command simply echos[^echo] the value of the line (`$_`), but it does so inside double quotes (the `\"`), which causes the shell to replace any environment variable with its value.

[^echo]: Note that we use /bin/echo here, instead of just plain echo, to get around an issue with the echo command in BSD (i.e., OSX).

And that's it!  Since the subsitution is being done by the shell itself, you can use either form for the environment variable (either `$VARIABLE` or `${VARIABLE}`), and the replacement is always done using the rules for the current shell.

Here's an example -- let's create a simple .ini type file, like so:

    username=$USER
    host=$HOSTNAME
    home-directory=$HOME
    current-directory=$PWD

When we run this file through our Perl one-liner, we get:

    perl -pe '$_=qx"/bin/echo -n \"$_\"";' < sample.ini
    username=btorpey
    host=btmac
    home-directory=/Users/btorpey
    current-directory=/Users/btorpey/blog/code/tailor

One thing to watch out for is that things can get a little hinky if your input file contains quotes, since the shell will interpret those, and probably not in the way you intend.  At least in my experience, that would be pretty rare -- but if you do get peculiar output that would be something to check.
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Remote Scripting with bash and ssh]]></title>
    <link href="http://btorpey.github.io/blog/2015/10/13/remote-scripting-with-bash-and-ssh/"/>
    <updated>2015-10-13T00:00:00-04:00</updated>
    <id>http://btorpey.github.io/blog/2015/10/13/remote-scripting-with-bash-and-ssh</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/multimonitors.jpg" width="370" height="245">

Nowadays it's pretty common for applications to be distributed across multiple
machines, which can be good for scalability and resilience.

But it does mean that we have more machines to monitor -- sometimes a LOT more!

Read on for a handy tip that will let you do a lot of those tasks from any old
session (and maybe lose some of those screens)!

<!-- more -->

For really simple tasks, remote shell access using ssh is fine.  But oftentimes
the tasks we need to perform on these systems are complicated enough that they
really should be scripted.

And especially when under pressure, (e.g.,  troubleshooting a problem in a
production system) it's good for these tasks to be automated. For one thing,
that means they can be tested ahead of time, so you don't end up doing the
dreaded `rm -rf *` by mistake.  (Don't laugh -- I've actually seen that happen).

Now, I've seen people do this by copying scripts to a known location on the
remote machines so they can be executed.  That works, but has some
disadvantages: it clutters up the remote system(s), and it creates one more
artifact that needs to be distributed and managed (e.g., updated when it
changes).

If you've got a bunch of related scripts, then you're going to have to bite the
bullet and manage them (perhaps with something like Puppet).

But for simple tasks, the following trick can come in very handy:

`
ssh HOST ‘bash –s ‘ < local_script.sh
`

What we're doing here is running bash remotely and telling bash to get its input
from stdin.  We're also redirecting local_script.sh to the stdin of ssh, which
is what the remote bash will end up reading.

As long as local_script.sh is completely self-contained, this works like a
charm.

For instance, to login to a remote machine and see if hyper-threading is enabled
on that machine:

`
ssh HOST 'bash -s' < ht.sh
`

Where ht.sh looks like this:

<div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span> (ht.sh)</span> <a href='/downloads/code/bash/ht.sh'>download</a></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c">#!/bin/bash</span>
</span><span class='line'>
</span><span class='line'><span class="c"># cribbed from http://unix.stackexchange.com/questions/33450/checking-if-hyperthreading-is-enabled-or-not</span>
</span><span class='line'><span class="c">#</span>
</span><span class='line'><span class="c"># NOTE:  There does not seem to be a good way to determine if HT is available but not enabled on a particular machine:</span>
</span><span class='line'><span class="c"># - &#39;ht&#39; flag in /proc/cpuinfo is unreliable</span>
</span><span class='line'><span class="c"># - lscpu could be used, but is not part of RH5</span>
</span><span class='line'><span class="c"># - dmidecode could be used, but requires root permissions</span>
</span><span class='line'><span class="c">#</span>
</span><span class='line'><span class="c"># So for now we just report whether HT is enabled or not</span>
</span><span class='line'>
</span><span class='line'><span class="nb">echo</span> -n <span class="k">${</span><span class="nv">HOSTNAME</span><span class="k">}</span>
</span><span class='line'>
</span><span class='line'><span class="nv">nproc</span><span class="o">=</span><span class="k">$(</span>grep -i <span class="s2">&quot;processor&quot;</span> /proc/cpuinfo | sort -u | wc -l<span class="k">)</span>
</span><span class='line'><span class="nv">phycore</span><span class="o">=</span><span class="k">$(</span>cat /proc/cpuinfo | egrep <span class="s2">&quot;core id|physical id&quot;</span> | tr -d <span class="s2">&quot;\n&quot;</span> | sed s/physical/<span class="se">\\</span>nphysical/g | grep -v ^<span class="nv">$ </span>| sort -u | wc -l<span class="k">)</span>
</span><span class='line'><span class="k">if</span> <span class="o">[</span> -z <span class="s2">&quot;$(echo &quot;</span><span class="nv">$phycore</span> *2<span class="s2">&quot; | bc | grep $nproc)&quot;</span> <span class="o">]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">   </span><span class="nb">echo</span> <span class="s2">&quot;: HT disabled&quot;</span>
</span><span class='line'><span class="k">else</span>
</span><span class='line'><span class="k">   </span><span class="nb">echo</span> <span class="s2">&quot;: HT enabled&quot;</span>
</span><span class='line'><span class="k">fi</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>


(The script above was cribbed from http://unix.stackexchange.com/a/33509 --
thanks, Nils!)


Of course, all the normal redirection rules apply -- you just have to keep in
mind that you're redirecting to ssh, which is then redirecting to bash on the
input side.  On the output side, it's reversed.

Give this a try the next time you need to do some quick tasks over ssh and
you'll be able to get rid of a few of those monitors!
</p>
]]></content>
  </entry>
  
</feed>
