<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: linux | Confessions of a Wall Street Programmer]]></title>
  <link href="http://btorpey.github.io/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://btorpey.github.io/"/>
  <updated>2019-07-15T11:22:46-04:00</updated>
  <id>http://btorpey.github.io/</id>
  <author>
    <name><![CDATA[Bill Torpey]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Memory Checking]]></title>
    <link href="http://btorpey.github.io/blog/2019/07/14/memory-checking/"/>
    <updated>2019-07-14T00:00:00-04:00</updated>
    <id>http://btorpey.github.io/blog/2019/07/14/memory-checking</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/memory-testing.jpg">

At my day job, I spend a fair amount of time working on software reliability.  One way to make software more reliable is to use memory-checking tools like valgrind's [memcheck](http://www.valgrind.org/info/tools.html#memcheck) and clang's [AddressSanitizer](https://github.com/google/sanitizers/wiki/AddressSanitizer) to detect memory errors at runtime.  

But these tools are typically not appropriate to use all the time -- valgrind causes programs to run much more slowly than normal, and AddressSanitizer needs a special instrumented build of the code to work properly.  So neither tool is typically well-suited for production code.

But there's another memory-checking tool that is "always on".  That tool is plain old `malloc`, and it is the subject of this article.

<!-- more -->

The [GNU C library](https://www.gnu.org/software/libc/) (glibc for short) provides implementations for the C standard library functions (e.g., `strlen` etc.) including functions that interface to the underlying OS (e.g., `open` et al.).  glibc also provides functions to manage memory, including `malloc`, `free` and their cousins, and in most code these memory management functions are among the most heavily used.

It's not possible to be a C programmer and not be reasonably familiar with the memory management functions in glibc.  But what is not so well-known is the memory-checking functionality built into the library.

It turns out that glibc contains two separate sets of memory management functions -- the core functions do minimal checking, and are significantly faster than the "debug" functions, which provide additional runtime checks.

The memory checking in `malloc` is controlled by an environment variable, named appropriately enough `MALLOC_CHECK_` (note the trailing underscore).  You can configure `malloc` to perform additional checking, and whether to print an error message and/or abort with a core file if it detects an error.  You can find full details at <http://man7.org/linux/man-pages/man3/mallopt.3.html>, but here's the short version:

Value | Impl | Checking | Message | Backtrace + mappings (since glibc 2.4+) | Abort w/core
------| ---- | -------- | ------ | ------ | ------
**default (unset)** | **Fast** | **Minimal** | **Detailed** | **Yes** | **Yes**
0 | Fast | Minimal | None |  No | No
1 | Slow | Full | Detailed | No | No
2 | Slow | Full | None | No | Yes
3 | Slow | Full | Detailed | Yes | Yes
5 | Slow | Full | Brief | No | Yes
7 | Slow | Full | Brief | Yes | Yes

<br>

What may be surprising is that the default behavior is for `malloc` to do at least minimal checking at runtime, and to **abort the executable with a core file** if those checks fail.  

This may or may not be what you want.  Given that the minimal checks in the fast implementation only detect certain specific errors, and that those errors (e.g., double free) tend not to cause additional problems, you may decide that a "no harm, no foul" approach is more appropriate (for example with production code where aborting with a core file is frowned upon ;-).

The other relevant point here is that setting `MALLOC_CHECK_` to any non-zero value causes `malloc` to use the slower heap functions that perform additional checks.  I've included a [sample benchmark program](https://github.com/WallStProg/malloc-check/blob/master/malloc-bench.cpp) that shows the additional checking adds about 30% to the overhead of the `malloc`/`free` calls.  (And while the benchmark program is dumb as dirt, its results are similar to results on "real-world" tests).

### Multi-threaded Performance
If the benchmark code is to be believed, the impact on performance of the extra checking when `MALLOC_CHECK_` is set to a non-zero value is **much** (as in an order of magnitude) greater when multiple threads are accessing the heap concurrently.  This would suggest that there is contention on the data structures used for full checking, over and above normal heap contention.

It would be nice if one could get a fast implementation with the option to output an error message and continue execution, but with the current[^rh7] implementation of glibc that doesn't appear to be possible.  If you want the fast implementation but you don't want to abort on errors, the only option is to turn off checking entirely (by explicitly setting `MALLOC_CHECK_` to 0).  

[^rh7]: Current for RedHat/CentOS 7 in any case, which is glibc 2.17.

Note also that the [documentation](http://man7.org/linux/man-pages/man3/mallopt.3.html) is a bit misleading:

> Since glibc 2.3.4, the default value for the M_CHECK_ACTION              parameter is 3.

While it's true that with no value specified for `MALLOC_CHECK_` an error will cause a detailed error message with backtrace and mappings to be output, along with an abort with core file, that is **NOT** the same as explicitly setting `MALLOC_CHECK_=3` -- that setting also causes `malloc` to use the slower functions that perform additional checks.

### "Minimal" vs. "Full" Checking

- In the table above, the "checking" setting for `MALLOC_CHECK_=0` is "minimal" -- the checks are still performed, but errors are simply not reported.
  - Note that it is not possible to completely disable checking -- minimal checking is *always* performed, even if the results are ignored. 
- The errors that can be detected with "minimal" checking are limited to a small subset of those detected with "full" checking -- sometimes even for the same error.  For instance, with minimal checking a double-free can be detected *only* if the second free occurs immediately after the first.  With full checking the double-free is detected even if there are intervening calls to `malloc` and `free`.

And, of course, the built-in checking in glibc can't detect a *lot* of errors that can be found with more robust tools, like [valgrind](http://www.valgrind.org/) and [AddressSanitizer](https://github.com/google/sanitizers/wiki/AddressSanitizer).  Nevertheless, `MALLOC_CHECK_` can be a useful adjunct to those tools for everyday use in development.

## Conclusions
- For typical development, it's probably best to explicitly set `MALLOC_CHECK_=3`.  This provides additional checking over and above the default setting, at the cost of somewhat poorer performance.
- For production use, you may want to decide whether the benefit of minimal checking is worth the possibility of having programs abort with errors that may be benign.  If the default is not appropriate, you basically have two choices:
  - Setting `MALLOC_CHECK_=1` will allow execution to continue after an error, but will at least provide a message that can be logged[^log] to provide a warning that things are not quite right, and trigger additional troubleshooting, but at the cost of somewhat poorer performance.
  - If you can't afford to give up any performance at all, you can set `MALLOC_CHECK=0`, but any errors detected will be silently ignored.
- Last but not least, if you're running multi-threaded code the performance penalty with full checking is potentially much more significant.  You'll probably want to benchmark your code  both with and without full checking if you're thinking of enabling full checking.

[^log]: The error message from glibc is written directly to the console (tty device), not to `stderr`, which means that it will not be redirected.  If you need the message to appear on stderr, you will need to [set another environment variable](https://bugzilla.redhat.com/show_bug.cgi?id=1519182):
    `export LIBC_FATAL_STDERR_=1`
    
## Code
The code for this article is available [here](https://github.com/WallStProg/malloc-check.git).  There's a benchmark program, which requires [Google Benchmark](https://github.com/google/benchmark).  There are also sample programs which demonstrate a double-free error that can be caught even with minimal checking (`double-free.c`), and which cannot (`double-free2.c`), and a simple script that ties everything together.  

## Footnotes





</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lots o' static]]></title>
    <link href="http://btorpey.github.io/blog/2017/09/17/lotso-static/"/>
    <updated>2017-09-17T00:00:00-04:00</updated>
    <id>http://btorpey.github.io/blog/2017/09/17/lotso-static</id>
    <content type="html"><![CDATA[<p><img class="left" src="/images/static-cat.jpg" width="250" height="188">

- Will be replaced with the ToC, excluding the "Contents" header
{:toc}

I've written before about [static analysis](/blog/categories/static-analysis/), but in those earlier posts I wasn't able to give specific examples of real-world code where static analysis is able to discover latent errors.

In the earlier articles I used a synthetic code-base [from ITC Research](https://github.com/regehr/itc-benchmarks) to test clang, cppcheck and PVS-Studio.  I also ran all three tools on the code-bases that I'm responsible for maintaining at my "day job", but I wasn't able to share detailed results from that analysis, given that the code is not public.

In this article, I want to expand the discussion of static analysis by diving into a real-world, open-source code base that I've been working with lately, with specific examples of the kinds of problems static analysis can expose.

<!-- more -->


## OpenMAMA
For this example, I'll be using the [OpenMAMA](http://openmama.org) source code.  OpenMAMA is an open-source messaging middleware framework that provides a high-level API for a bunch of messaging transports, including open-source (Qpid/AMQP, ZeroMQ) and commercial (DataFabric, Rendezvous, Solace, etc).

OpenMAMA is an interesting project -- it started back in 2004 with Wombat Financial Software, which was attempting to sell its market-data software, but found it to be tough sledding.  While Wombat's software performed better and was less expensive than Tibco's Rendezvous (the de-facto standard at the time), no one wanted to rewrite their applications to target an API from a small company that might not be around in a couple of years.

So Wombat developed an open API which could sit on top of any messaging middleware, and they called it MAMA, for Middleware Agnostic Messaging API.  They also developed bindings for Rendezvous, in addition to their own software, so that prospective customers would have a warm and fuzzy feeling that they could write their applications once, and seamlessly switch out the underlying middleware software with little or no changes to their code.

That strategy worked well enough that in 2008 Wombat was acquired by the New York Stock Exchange, which renamed the software "Data Fabric" and used it as the backbone of their market-data network (SuperFeed).

When the company I was working for was also acquired by NYSE in 2009 I was tasked with replacing our existing middleware layer with the Mama/Wombat middleware, and in the process I came to appreciate the "pluggable" architecture of MAMA -- it doesn't make the issues related to different messaging systems go away, but it does provide a framework for dealing with them.

In 2011 NYSE Technologies donated OpenMAMA to the Linux Foundation.  Then, in 2014, the Wombat business was sold by NYSE to [Vela Trading Technologies](https://www.velatradingtech.com/) (née SR Labs), which provides the proprietary Data Fabric middleware, and is also the primary maintainer for OpenMAMA.  There are a number of different [open-source and commercial implementations of OpenMAMA](http://www.openmama.org/what-is-openmama/supported-software).

Which brings us to the present day -- I've recently started working with OpenMAMA again, so it seemed like a good idea to use that code as an example of how to use static analysis tools to identify latent bugs.

And, just to be clear, this is not a criticism of OpenMAMA -- it's an impressive piece of work, and has proven itself in demanding real-world situations.  

## Following along

The analysis presented here is based on OpenMAMA release 6.2.1, which can be found [here](https://github.com/OpenMAMA/OpenMAMA/releases/tag/OpenMAMA-6.2.1-release).

I used [cppcheck version 1.80](http://cppcheck.sourceforge.net/) and [clang version 5.0.0](http://releases.llvm.org/download.html#5.0.0).

Check out the [earlier articles in this series](/blog/categories/static-analysis/) for more on building and running the various tools, including a bunch of helper scripts in the [GitHub repo](https://github.com/btorpey/static).

For the OpenMAMA analysis, I first built OpenMAMA using [Bear](https://github.com/rizsotto/Bear) to create a compilation database from the scons build:  

~~~bash
bear scons blddir=build product=mama with_unittest=n \
middleware=qpid with_testtools=n with_docs=n
~~~

With the compilation database in place, I ran the following scripts[^tools], redirecting their output to create the result files:

~~~bash
cc_cppcheck.sh -i common/c_cpp/src/c/ -i mama/c_cpp/src/c/ -c cc_clangcheck.sh -i common/c_cpp/src/c/ -i mama/c_cpp/src/c/ -c cc_clangtidy.sh -i common/c_cpp/src/c/ -i mama/c_cpp/src/c/ -c 
~~~

The results from running the tools on OpenMAMA can also be found in [the repo](https://github.com/btorpey/static/tree/master/openmama), along with a `compile_commands.json` file that can be used without the need to build OpenMAMA from source[^mamabuild].  To do that, use the following commands:

    cd [directory]
    git clone https://github.com/OpenMAMA/OpenMAMA.git
    git clone https://github.com/btorpey/static.git
    export PATH=$(/bin/pwd)/static/scripts:$PATH
    cp static/openmama/* OpenMAMA
    cd OpenMAMA
    cc_cppcheck.sh -i common/c_cpp/src/c/ -i mama/c_cpp/src/c/ -c 

I use the wonderful [Beyond Compare](/blog/2013/01/29/beyond-compare/) to, well, compare the results from different tools.

[^tools]: Simply clone the [GitHub repo](https://github.com/btorpey/static) to any directory, and then add the `scripts` directory to your `PATH`.

[^mamabuild]: OpenMAMA has its share of prerequisites -- you can get a full list [here](https://openmama.github.io/openmama_build_instructions.html).

## False Positives
Before we do anything else, let's deal with the elephant in the room -- false positives.  As in, warning messages for code that is actually perfectly fine.  Apparently, a lot of people have been burned by "lint"-type programs with terrible signal-to-noise ratios.  I know -- I've been there too.

Well, let me be clear -- these are not your father's lints.  I've been running these tools on a lot of real-world code for a while now, and there are essentially  NO false positives.  If one of these tools complains about some code, there's something wrong with it, and you really want to fix it.

## Style vs. Substance
cppcheck includes a lot of "style" checks, although the term can be misleading  -- there are a number of "style" issues that can have a significant impact on quality.

One of them crops up all over the place in OpenMAMA code, and that is the "The scope of the variable '\<name>' can be reduced" messages.  The reason for these is because of OpenMAMA's insistence on K&R-style variable declarations (i.e., all block-local variables must be declared before any executable statements).  Which, in turn, is caused by OpenMAMA's decision to support several old and broken Microsoft compilers[^vs].

[^vs]: The list of supported platforms for OpenMAMA is [here](https://openmama.github.io/openmama_supported_platforms.html).  You can also find a lot of griping on the intertubes about Microsoft's refusal to support C99, including [this rather weak response](https://visualstudio.uservoice.com/forums/121579-visual-studio-ide/suggestions/2089423-c99-support) from Herb Sutter.  Happily, VS 2013 ended up supporting (most of) C99\. 

The consensus has come to favor declaring variables as close to first use as possible, and that is part of the [C++ Core Guidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#es21-dont-introduce-a-variable-or-constant-before-you-need-to-use-it).  The only possible down-side to this approach is that it makes it easier to inadvertently declare "shadow" variables (i.e., variables with the same name in both inner and outer scopes), but modern compilers can flag shadow variables, which mitigates this potential problem (see my earlier article ["Who Knows What Evil Lurks..."](/blog/2015/03/17/shadow/) for more).

Some other "style" warnings produced by cppcheck include:

> \[mama/c_cpp/src/c/bridge/qpid/transport.c:1413]: (style) Consecutive return, break, continue, goto or throw statements are unnecessary.

These are mostly benign, but reflect a lack of understanding of what statements like `continue` and `return` do, and can be confusing.
<br>
<br>

> \[common/c_cpp/src/c/list.c:295 -> common/c_cpp/src/c/list.c:298]: (style) Variable 'rval' is reassigned a value before the old one has been used.

There are a lot of these in OpenMAMA, and most of them are probably caused by the unfortunate decision to standardize on K&R-style local variable declarations, but in other cases this can point to a potential logic problem.  (Another good reason to avoid K&R-style declarations).

<br>
Similar, but potentially more serious is this one:

> \[mama/c_cpp/src/c/bridge/qpid/transport.c:275]: (style) Variable 'next' is assigned a value that is never used.

Maybe the variable was used in an earlier version of the code, but is no longer needed.  Or maybe we ended up using the wrong variable when we mean to use `next`.

## Dead Code

There are also cases where the analyzer can determine that the code as written is meaningless

> \[mama/c_cpp/src/c/bridge/qpid/subscription.c:179]: (style) A pointer can not be negative so it is either pointless or an error to check if it is.

If something cannot happen, there is little point to testing for it -- so testing for impossible conditions is almost always a sign that something is wrong with the code.

Here are a few more of the same ilk:

> \[mama/c_cpp/src/c/dictionary.c:323]: (style) Checking if unsigned variable '*size' is less than zero.

<!-- -->
> \[mama/c_cpp/src/c/statslogger.c:731]: (style) Condition 'status!=MAMA_STATUS_OK' is always false

<!-- -->
> \[mama/c_cpp/src/c/dqstrategy.c:543]: (style) Redundant condition: If 'EXPR == 3', the comparison 'EXPR != 2' is always true.

Whether these warnings represent real bugs is a question that needs to be answered on a case-by-case basis, but I hope we can agree that they at the very least represent a ["code smell"](https://en.wikipedia.org/wiki/Code_smell), and the fewer of these in our code, the better.

## Buffer Overflow
There are bugs, and there are bugs, but bugs that have a "delayed reaction", are arguably the worst, partly because they can be so hard to track down.  Buffer overflows are a major cause of these kinds of bugs -- a buffer overflow can trash return addresses on the stack causing a crash, or worse they can alter the program's flow in ways that seem completely random.

Here's an example of a buffer overflow in OpenMAMA that was detected by cppcheck:

> \[common/c_cpp/src/c/strutils.c:632]: (error) Array 'version.mExtra[16]' accessed at index 16, which is out of bounds.


Here's the offending line of code:

~~~
    version->mExtra[VERSION_INFO_EXTRA_MAX] = '\0';
~~~


And here's the declaration:

~~~c
    char mExtra[VERSION_INFO_EXTRA_MAX];
~~~


It turns out that this particular bug was fixed subsequent to the release -- the bug report is [here](https://github.com/OpenMAMA/OpenMAMA/pull/310).  Interestingly, the bug report mentions that the bug was found using clang's Address Sanitizer,  which means that code must have been executed to expose the bug.     Static analyzers like cppcheck can detect this bug without the need to run the code, which is a big advantage of static analysis.  In this example, cppcheck can tell at compile-time that the access is out-of-bounds, since it knows the size of mExtra.

Of course, a static analyzer like cppcheck can't detect *all* buffer overflows -- just the ones that can be evaluated at compile-time.  So, we still need Address Sanitizer, or valgrind, or some other run-time analyzer, to detect overflows that depend on the run-time behavior of the program.  But I'll take all the help I can get, and detecting at least some of these nasty bugs at compile-time is a win.

## NULL pointer dereference
In contrast to the buffer overflow type of problem, dereferencing a NULL pointer is not mysterious at all -- you're going down hard, right now.

So, reasonable programmers insert checks for NULL pointers, but reasonable is not the same as perfect, and sometimes we get it wrong.

> \[mama/c_cpp/src/c/msg.c:3619] -> [mama/c_cpp/src/c/msg.c:3617]: (warning, inconclusive) Either the condition '!impl' is redundant or there is possible null pointer dereference: impl.

Here's a snip of the code in question -- see if you can spot the problem:

~~~c
3613    mamaMsgField
3614    mamaMsgIterator_next (mamaMsgIterator iterator)
3615    {
3616        mamaMsgIteratorImpl* impl         = (mamaMsgIteratorImpl*)iterator;
3617        mamaMsgFieldImpl*    currentField = (mamaMsgFieldImpl*) impl->mCurrentField;
3618
3619        if (!impl)
3620            return (NULL);
~~~

cppcheck works similarly to other static analyzers when checking for possible NULL pointer dereference -- it looks to see if a pointer is checked for NULL, and if it is, looks for code that dereferences the pointer outside the scope of that check.

In this case, the code checks for `impl` being NULL, but not until it has already dereferenced the pointer.  cppcheck even helpfully ties together the check for NULL and the (earlier) dereference. (Ahem -- yet another reason to avoid K&R-style declarations).

## Leaks
Similarly to checking for NULL pointers, detecting leaks is more of a job for valgrind, Address Sanitizer or some other run-time analysis tool.  However, that doesn't mean that static analysis can't give us a head-start on getting rid of our leaks.

For instance, cppcheck has gotten quite clever about being able to infer run-time behavior at compile-time, as in this example:

> \[mama/c_cpp/src/c/transport.c:269]: (error) Memory leak: transport
<br>
> \[mama/c_cpp/src/c/transport.c:278]: (error) Memory leak: transport
Here's the code:

~~~c
253 mama_status
254 mamaTransport_allocate (mamaTransport* result)
255 {
256     transportImpl*  transport    =   NULL;
257     mama_status     status       =   MAMA_STATUS_OK;
258
259
260     transport = (transportImpl*)calloc (1, sizeof (transportImpl ) );
261     if (transport == NULL)  return MAMA_STATUS_NOMEM;
262
263     /*We need to create the throttle here as properties may be set
264      before the transport is actually created.*/
265     if (MAMA_STATUS_OK!=(status=wombatThrottle_allocate (&self->mThrottle)))
266     {
267         mama_log (MAMA_LOG_LEVEL_ERROR, "mamaTransport_allocate (): Could not"
268                   " create throttle.");
269         return status;
270     }
271
272     wombatThrottle_setRate (self->mThrottle,
273                            MAMA_DEFAULT_THROTTLE_RATE);
274
275     if (MAMA_STATUS_OK !=
276        (status = wombatThrottle_allocate (&self->mRecapThrottle)))
277     {
278         return status;
279     }
280
281     wombatThrottle_setRate (self->mRecapThrottle,
282                             MAMA_DEFAULT_RECAP_THROTTLE_RATE);
283
284     self->mDescription          = NULL;
285     self->mLoadBalanceCb        = NULL;
286     self->mLoadBalanceInitialCb = NULL;
287     self->mLoadBalanceHandle    = NULL;
288     self->mCurTransportIndex    = 0;
289     self->mDeactivateSubscriptionOnError = 1;
290     self->mGroupSizeHint        = DEFAULT_GROUP_SIZE_HINT;
291     *result = (mamaTransport)transport;
292
293     self->mName[0] = '\0';
294
295     return MAMA_STATUS_OK;
296 }
~~~

cppcheck is able to determine that the local variable `transport` is never assigned in the two early returns, and thus can never be freed.
<br>

Not to be outdone, clang-tidy is doing some kind of flow analysis that allows it to catch this one:

> \[mama/c_cpp/src/c/queue.c:778]: warning: Use of memory after it is freedHere's a snip of the code that clang-tidy is complaining about:

~~~ c
651 mama_status652 mamaQueue_destroy (mamaQueue queue)653 {654     mamaQueueImpl* impl = (mamaQueueImpl*)queue;655     mama_status    status = MAMA_STATUS_OK;...776         free (impl);777778         mama_log (MAMA_LOG_LEVEL_FINEST, "Leaving mamaQueue_destroy for queue 0x%X.", queue);779         status = MAMA_STATUS_OK;780     }781782    return status;783 }
~~~
clang-tidy understands that `queue` and `impl` are aliases for the same variable, and thus knows that it is illegal to access `queue` after `impl` has been freed.  In this case, the access causes no problems, because we're only printing the address, but clang-tidy can't know that[^interproc].

[^interproc]: Unless it knows what `mama_log` does.  It turns out that clang-tidy can do inter-procedural analysis, but only within a single translation unit.  There is some work ongoing to add support for analysis across translation units by Gábor Horvath et al. -- for more see ["Cross Translational Unit Analysis in Clang Static Analyzer: Prototype and Measurements"](http://llvm.org/devmtg/2017-03//2017/02/20/accepted-sessions.html#7).


## Pointer Errors
I've <del>ranted</del> written [before](/blog/2014/09/23/into-the-void/) on how much I hate `void*`'s.  For better or worse, the core OpenMAMA code is written in C, so there are a whole bunch of casts between `void*`s and "real" pointers that have the purpose of encapsulating the internal workings of the internal objects managed by the code.

In C this is about the best that can be done, but it can be hard to keep things straight, which can be a source of errors (like this one):

> \[mama/c_cpp/src/c/fielddesc.c:76]: (warning) Assignment of function parameter has no effect outside the function. Did you forget dereferencing it?And here's the code:

~~~ c
65  mama_status66  mamaFieldDescriptor_destroy (mamaFieldDescriptor descriptor)67  {68      mamaFieldDescriptorImpl* impl = (mamaFieldDescriptorImpl*) descriptor;6970      if (impl == NULL)71          return MAMA_STATUS_OK;7273      free (impl->mName);74      free (impl);7576      descriptor = NULL;77      return MAMA_STATUS_OK;78  }
~~~

Of course `mamaFieldDescriptor` is defined as a `void*`, so it's perfectly OK to set it to NULL, but since it's passed by value, the assignment has no effect other than to zero out the copy of the parameter on the stack.

## But Wait, There's More!
The preceding sections go into detail about specific examples of serious errors detected by cppcheck and clang.  But, these are very much the tip of the iceberg.

Some of the other problems detected include:

- use of non-reentrant system functions (e.g., `strtok`) in multi-threaded code;
- use of obsolete functions (e.g., `gethostbyname`);
- incorrect usage of `printf`-style functions;
- incorrect usage of `strcpy`-style functions (e.g., leaving strings without terminating NULL characters);
- incorrect usage of varargs functions;
- different parameter names in function declarations vs. definitions;

Some of these are nastier than others, but they are all legitimate problems and should be fixed.

The full results for both tools are available in the [GitHub repo](https://github.com/btorpey/static/tree/master/openmama), so it's easy to compare the warnings against the code.

## Conclusion
The state of the art in static analysis keeps advancing, thanks to people like Daniel Marjamäki and the rest of the [cppcheck team](https://github.com/danmar/cppcheck/graphs/contributors), and Gábor Horváth and the [team supporting clang](https://github.com/llvm-mirror/clang/graphs/contributors).

In particular, the latest releases of cppcheck and clang-tidy are detecting errors that previously could only be found by run-time analyzers like valgrind and Address Sanitizer.  This is great stuff, especially given how easy it is to run static analysis on your code.

The benefits of using one (or more) static analysis tools just keep getting more and more compelling -- if you aren't using one of these tools, I hope this will encourage you to do so.

If you found this article interesting or helpful, you might want to also check out the other posts in [this series](/blog/categories/static-analysis/).  And please leave a comment below or [drop me a line](<mailto:wallstprog@gmail.com>) with any questions, suggestions, etc.

<hr>
## Footnotes








</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[We Don't Need No Stinkin' Databases]]></title>
    <link href="http://btorpey.github.io/blog/2017/05/10/join/"/>
    <updated>2017-05-10T00:00:00-04:00</updated>
    <id>http://btorpey.github.io/blog/2017/05/10/join</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/Gold_Hat_portrayed_by_Alfonso_Bedoya.jpg" width="220" height="162">

I've been working on performance analysis recently, and a large part of that is scraping log files to capture interesting events and chart them.

I'm continually surprised by the things that you can do using plain old bash and his friends, but this latest one took the cake for me.

<!-- more -->

Did you know that Linux includes a utility named `join`?  Me neither.  Can you guess what it does?  Yup, that's right -- it does the equivalent of a database join across plain text files.

Let me clarify that with a real-world example -- one of the datasets I've been analyzing counts the number of messages sent and received in a format roughly like this:

|Timestamp| Recv |
|:--------|-----:|
| HH:MM:SS| x |

<br>
Complicating matters is that sent and received messages are parsed out separately, so we also have a separate file that looks like this:

|Timestamp| Send |
|:--------|-----:|
| HH:MM:SS| y |

<br>
But what we really want is something like this:

|Timestamp| Recv | Send |
|:--------|-----:|------:|
| HH:MM:SS| x | y |

<br>
Here are snips from the two files:

    $ cat recv.txt
    Timestamp	Recv
    2016/10/25-16:04:58	7
    2016/10/25-16:04:59	1
    2016/10/25-16:05:00	7
    2016/10/25-16:05:01	9
    2016/10/25-16:05:28	3
    2016/10/25-16:05:31	9
    2016/10/25-16:05:58	3
    2016/10/25-16:06:01	9
    2016/10/25-16:06:28	3
    $ cat send.txt
    Timestamp	Send
    2016/10/25-16:04:58	6
    2016/10/25-16:05:01	18
    2016/10/25-16:05:28	3
    2016/10/25-16:05:31	9
    2016/10/25-16:05:58	3
    2016/10/25-16:06:01	9
    2016/10/25-16:06:28	3
    2016/10/25-16:06:31	9
    2016/10/25-16:06:58	3


I had stumbled across the `join` command and thought it would be a good way to combine the two files.

Doing a simple join with no parameters gives this:

    $ join recv.txt send.txt
    Timestamp Recv Send
    2016/10/25-16:04:58 7 6
    2016/10/25-16:05:01 9 18
    2016/10/25-16:05:28 3 3
    2016/10/25-16:05:31 9 9
    2016/10/25-16:05:58 3 3
    2016/10/25-16:06:01 9 9
    2016/10/25-16:06:28 3 3

As you can see, we're missing some of the measurements.  This is because by default `join` does an [inner join](https://en.wikipedia.org/wiki/Join_(SQL)#Inner_join) of the two files (the intersection, in set theory).

That's OK, but not really what we want.  We really need to be able to reflect each value from both datasets, and for that we need an [outer join](https://en.wikipedia.org/wiki/Join_(SQL)#Outer_join), or union.

It turns out that `join` can do that too, although the syntax is a bit more complicated:

    $ join -t $'\t' -o 0,1.2,2.2 -a 1 -a 2 recv.txt send.txt
    Timestamp	Recv	Send
    2016/10/25-16:04:58	7	6
    2016/10/25-16:04:59	1
    2016/10/25-16:05:00	7
    2016/10/25-16:05:01	9	18
    2016/10/25-16:05:28	3	3
    2016/10/25-16:05:31	9	9
    2016/10/25-16:05:58	3	3
    2016/10/25-16:06:01	9	9
    2016/10/25-16:06:28	3	3
    2016/10/25-16:06:31		9
    2016/10/25-16:06:58		3


A brief run-down of the parameters is probably in order:

|Parameter | Description
|----------|------------
| `-t $'\t'` | The `-t` parameter tells `join` what to use as the separator between fields.  The tab character is the best choice, as most Unix utilities assume that by default, and both Excel and Numbers can work with tab-delimited files.<br>The leading dollar-sign is a [trick](https://unix.stackexchange.com/a/46931/198530) used to to pass a literal tab character on the command line  .
| `-o 0,1.2,2.2` | Specifies which fields to output.  In this case, we want the "join field" (in this case, the first field from both files), then the second field from file #1, then the second field from file #2.
| `-a 1` | Tells `join` that we want **all** the fields from file #1.
| `-a 2` | Ditto for file #2.

<br>
As you can probably see, you can also get fancy and do things like left outer joins and right outer joins, depending on the parameters passed.

Of course, you could easily import these text files into a "real" database and generate reports that way.  But, you can accomplish a surprising amount of data manipulation and reporting with Linux's built-in utilities and plain old text files.

### Acknowledgements
I couldn't remember where I had originally seen the `join` command, but recently found it again in a [nice post by Alexander Blagoev](http://ablagoev.github.io/linux/adventures/commands/2017/02/19/adventures-in-usr-bin.html).  Check it out for even more obscure commands!  And, thanks Alexander!  

And thanks also to Igor for his own [very nice post](http://shiroyasha.io/coreutils-that-you-might-not-know.html) that led  me back to Alexander's.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Even Mo' Static]]></title>
    <link href="http://btorpey.github.io/blog/2016/11/12/even-mo-static/"/>
    <updated>2016-11-12T00:00:00-05:00</updated>
    <id>http://btorpey.github.io/blog/2016/11/12/even-mo-static</id>
    <content type="html"><![CDATA[<p><img class="left" src="/images/vandergraaf.jpg" width="139" height="122">

- Will be replaced with the ToC, excluding the "Contents" header
{:toc}

A while back I wrote [an article](/blog/2016/04/07/mo-static/) that compared cppcheck and clang's static analyzers (clang-check and clang-tidy).  The folks who make [PVS-Studio](http://www.viva64.com/en/pvs-studio/) (the guys with the unicorn mascot that you've probably been seeing a lot of lately) saw the article, and suggested that I take a look at their Linux port, which was then in beta test, and write about it.

So I did.  Read on for an overview of PVS-Studio, and how it compared to [cppcheck](http://cppcheck.sourceforge.net/).

<!-- more -->

In [the earlier article](/blog/2016/04/07/mo-static/), I used a [benchmark suite](https://github.com/regehr/itc-benchmarks) developed by Toyota ITC, and written about by [John Regehr](http://blog.regehr.org/archives/1217), who is a professor of Computer Science at the University of Utah.  The ITC suite consists of code that is specially written to exhibit certain errors that can be detected by static analysis, so that the code can be used to evaluate the performance of different tools.

In this article, I am going to use the same test suite to evaluate  PVS-Studio, and to compare it against cppcheck.  I'll also talk about my experience using both tools to analyze two relatively large real-world codebases that I help maintain as part of my day job.

## TL;DR
Using any static analysis tool is better than using none, and in general the more the merrier.  Each tool has its own design philosophy, and corresponding strengths and weaknesses.

Daniel Marjamäki[^daniel] and the maintainers of [cppcheck](http://cppcheck.sourceforge.net/) have done a terrific job creating a free tool that can go head-to-head with expensive commercial offerings.  You can't go wrong with cppcheck, either as a gentle introduction to static analysis, or as the one-and-only tool for the budget-conscious.  But don't take my word for it -- the Debian project uses cppcheck as part of its [Debian Automated Code Analysis](https://qa.debian.org/daca/) project to check over 100GB of C++ source code.

[^daniel]: Daniel was recently interviewed on [CppCast](http://cppcast.com/2016/11/daniel-marjamaki/). 

[PVS-Studio](http://www.viva64.com/en/pvs-studio/) is also a terrific tool, but it is definitely _not_ free.  (When a product [doesn't have published prices](http://www.viva64.com/en/order/), you know it's going to cost serious money).

Whether PVS-Studio is worth the price is a judgement call, but if it can find just one bug that would have triggered a crash in production it will have paid for itself many times over. 

And while PVS-Studio doesn't appear to have been adopted by a high-profile project like Debian, the folks who make it are certainly not shy about running various open-source projects through their tool and [reporting the results](http://www.viva64.com/en/inspections/).  

So, if your budget can handle it, use both.  If money is a concern, then you may want to start out with cppcheck and use that to help build a case for spending the additional coin that it will take to include commercial tools like PVS-Studio in your toolbox.

Note also that PVS-Studio offers a trial version[^free], so you can give it a go on your own code, which is, after all, the best way to see what the tool can do.  And, if you use the provided [helper scripts](/pages/REAME.md/index.html) ([repo here](https://github.com/btorpey/static)), your results will be in a format that makes it easy to compare the tools.

[^free]: The folks at PVS-Studio asked me to mention that they've also recently introduced a free version of their software for educational purposes. The free version does have some strings attached, see [this post](http://www.viva64.com/en/b/0457/) for details.

## Methodology
In comparing cppcheck and PVS-Studio, I used the ITC test suite that I wrote about in an [earlier article](/blog/2016/04/07/mo-static/).  I also used both tools to analyze real-world code bases which I deal with on a day-to-day basis and that I am intimately familiar with.

### ITC test suite
The ITC test suite that I've been using to compare static analyzers is intended to provide a common set of source files that can be used as input to various static analysis tools.  It includes both real errors, as well as "false positives" intended to trick the tools into flagging legitimate code as an error.

So far, so good, and it's certainly very helpful to know where the errors are (and are not) when evaluating a static analysis tool.  

#### Caveats
In my email discussion with Andrey Karpov of PVS, he made the point that not all bugs are equal, and that a "checklist" approach to comparing static analyzers may not be the best.  I agree, but being able to compare analyzers on the same code-base can be very helpful, not least for getting a feel for how the tools work.

Your mileage can, and will, vary, so it makes sense to get comfortable with different tools and learn what each does best.  And there's no substitute for running the tools on your own code.  (The [helper scripts](/pages/REAME.md/index.html) ([repo here](https://github.com/btorpey/static)) may, well, help).

##### Specific issues 
The ITC test suite includes some tests for certain categories of errors that are more likely to manifest themselves at run-time, as opposed to compile-time.    

For instance, the ITC suite includes a relatively large number of test cases designed to expose memory-related problems.  These include problems like leaks, double-free's, dangling pointers, etc.

That's all very nice, but in the real world memory errors are often not that clear-cut, and depend on the dynamic behavior of the program at run-time.  Both valgrind's [memcheck](http://valgrind.org/info/tools.html#memcheck) and clang's [Address Sanitizer](http://clang.llvm.org/docs/AddressSanitizer.html) do an excellent job of detecting memory errors at run-time, and I use both regularly.

But run-time analyzers can only analyze code that actually runs, and memory errors can hide for quite a long time in code that is rarely executed (e.g., error & exception handlers). So, even though not all memory errors can be caught at compile-time, the ability to detect at least some of them can very helpful.  

A similar situation exists with regard to concurrency (threading) errors -- though in this case neither tool detects *any* of the concurrency-related errors seeded in the ITC code.  This is, I think, a reasonable design decision  -- the subset of threading errors that can be detected at compile-time is so small that it's not really worth doing (and could give users of the tool a false sense of security).  For concurrency errors, you again will probably be better off with something like clang's [Thread Sanitizer](http://clang.llvm.org/docs/ThreadSanitizer.html) or valgrind's [Data Race Detector](http://valgrind.org/info/tools.html#drd).

Also, in the interest of full disclosure, I have spot-checked some of the ITC code, but by no means all, to assure myself that its diagnostics were reasonable. 

With those caveats out of the way, though, the ITC test suite does provide at least a good starting point towards a comprehensive set of test cases that can be used to exercise different static analyzers.

The results of running PVS-Studio (and other tools) against the ITC code can be found in the [samples directory of the repo](https://github.com/btorpey/static/tree/master/samples).

## Real-world test results
I also ran both cppcheck and PVS-Studio on the code bases that I maintain as part of my day job, to get an idea of how the tools compare in more of a real-world situation.  While I can't share the detailed comparisons, following are some of the major points.

For the most part, both cppcheck and PVS-Studio reported similar warnings on the same code, with a few exceptions (listed following). 

cppcheck arguably does a better job of flagging "style" issues -- and while some of these warnings are perhaps a bit nit-picky, many are not:

- one-argument ctor's not marked `explicit` 
- functions that can/should be declared `static` or `const`
- use of post-increment on non-primitive types 
- use of obsolete or deprecated functions
- use of C-style casts

PVS-Studio, on the other hand, appears to include more checks for issues that aren't necessarily problems with the use of C++ per se, but things that would be a bug, or at least a "code smell", in any language.

A good example of that is PVS-Studio's warning on similar or identical code sequences (potentially indicating use of the copy-paste anti-pattern -- I've written about that [before](/blog/2014/09/21/repent/)).

Some other PVS-Studio "exclusives" include: 

- classes that define a copy ctor without `operator=`, and vice-versa
- potential floating-point problems[^float], e.g., comparing floating-point values for an exact match using `==`
- empty `catch` clauses
- catching exceptions by value rather than by reference

Both tools did a good job of identifying potentially suspect code, as well as areas where the code could be improved.

[^float]: See [here](http://blog.reverberate.org/2014/09/what-every-computer-programmer-should.html) and [here](http://floating-point-gui.de/) for an explanation of how floating-point arithmetic can produce unexpected results if you're not careful.

## False positives
False positives (warnings on code that is actually correct) are not really a problem with either cppcheck or PVS-Studio.  The few warnings that could be classified as false positives indicate code that is at the very least suspect -- in most cases you're going to want to change the code anyway, if only to make it clearer.

If you still get more false positives than you can comfortably deal with, or if you want to stick with a particular construct even though it may be suspect, both tools have mechanisms to suppress individual warnings, or whole classes of errors.  Both tools are also able to silence warnings either globally, or down to the individual line of code, based on inline comments.

## Conclusion
If you care about building robust, reliable code in C++ then you would be well-rewarded to include static analysis as part of your development work-flow.  

Both [PVS-Studio](http://www.viva64.com/en/pvs-studio/) and [cppcheck](http://cppcheck.sourceforge.net/) do an excellent job of identifying potential problems in your code.  It's almost like having another set of eyeballs to do code review, but with the patience to trace through all the possible control paths, and with a voluminous knowledge of the language, particularly the edge cases and "tricky bits".

Having said that, I want to be clear that static analysis is not a substitute for the dynamic analsyis provided by tools like valgrind's [memcheck](http://valgrind.org/info/tools.html#memcheck) and [Data Race Detector](http://valgrind.org/info/tools.html#drd), or clang's [Address Sanitizer](http://clang.llvm.org/docs/AddressSanitizer.html) and [Thread Sanitizer](http://clang.llvm.org/docs/ThreadSanitizer.html).  You'll want to use them too, as there are certain classes of bugs that can only be detected at run-time.

I hope you've found this information helpful.  If you have, you may want to check out some of my earlier articles, including:

- [Mo' Static](/blog/2016/04/07/mo-static/)
- [Static Analysis with clang](/blog/2015/04/27/static-analysis-with-clang/)
- [Using clang's Address Sanitizer](/blog/2014/03/27/using-clangs-address-sanitizer/)
- [Who Knows what Evil Lurks...](/blog/2015/03/17/shadow/)

Last but not least, please feel free to [contact me](<mailto:wallstprog@gmail.com>) directly, or post a comment below, if you have questions or something to add to the discussion.

## Appendix: Helper scripts and sample results

I've posted the [helper scripts](/pages/REAME.md/index.html) I used to run PVS-Studio, as well as the results of running those scripts on the ITC code, in the [repo](https://github.com/btorpey/static).

## Appendix: Detailed test results

The following sections describe a subset of the tests in the ITC code and how both tools respond to them.

### Bit Shift errors
{:.no_toc}
For the most part, PVS-Studio and cpphceck both do a good job of detecting errors related to bit shifts. Neither tool detects all the errors seeded in the benchmark code, although they miss different errors.

### Buffer overrun/underrun errors
{:.no_toc}
cppcheck appears to do a more complete job than PVS-Studio of detecting buffer overrrun and underrun errors, although it is sometimes a bit "off" -- reporting errors on lines that are in the vicinity of the actual error, rather than on the actual line.  cppcheck also reports calls to functions that generate buffer errors, which is arguably redundant, but does no harm.

PVS-Studio catches some of the seeded errors, but misses several that cppcheck detects.

While not stricly speaking an overrun error, cppcheck can also detect some errors where code overwrites the last byte in a null-terminated string.

### Conflicting/redundant conditions
{:.no_toc}
Both cppcheck and PVS-Studio do a good job of detecting conditionals that always evaluate to either true or false, with PVS-Studio being a bit better at detecting complicated conditions composed of contstants.

On the other hand, cppcheck flags redundant conditions (e.g., `if (i<5 && i<10)`), which PVS-Studio doesn't do. 

### Loss of integer precision
{:.no_toc}
Surprisingly, neither tool does a particularly good job of detecting loss of integer precision (the proverbial "ten pounds of bologna in a five-pound sack" problem ;-)

#### Assignments
{:.no_toc}
I say surprisingly because these kinds of errors would seem to be relatively easy to detect.  Where both tools seem to fall short is to assume that just because a value fits in the target data type, the assignment is valid -- but they fail to take into account that such an assignment can lose precision.

I wanted to convince myself that the ITC code was correct, so I pasted some of the code into a small test program:

<div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span> (test1.c)</span> <a href='/downloads/code/static/pvs/test1.c'>download</a></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="cp">#include &lt;stdio.h&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="kt">int</span> <span class="n">sink</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="kt">void</span> <span class="nf">data_lost_001</span> <span class="p">()</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>	<span class="kt">char</span> <span class="n">ret</span><span class="p">;</span>
</span><span class='line'>	<span class="kt">short</span> <span class="n">a</span> <span class="o">=</span> <span class="mh">0x80</span><span class="p">;</span>
</span><span class='line'>	<span class="n">ret</span> <span class="o">=</span> <span class="n">a</span><span class="p">;</span><span class="cm">/*Tool should detect this line as error*/</span> <span class="cm">/*ERROR:Integer precision lost because of cast*/</span>
</span><span class='line'>        <span class="n">sink</span> <span class="o">=</span> <span class="n">ret</span><span class="p">;</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>   <span class="n">data_lost_001</span><span class="p">();</span>
</span><span class='line'>   <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Value of sink=%d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">sink</span><span class="p">);</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

When you run this program, you'll get the following output:

    $ gcc test1.c && ./a.out
    Value of sink=-128

So, `a` has the value 128, but when `a` is assigned to the (signed) char `ret`,  the bit pattern `0x80` is interpreted in the context of a (signed) char, and the sign is lost.  If `ret` had been declared as an unsigned char, then the assigment would not lose the sign of `a`.

#### Arithmetic expressions
{:.no_toc}
cppcheck does do a slightly better job of detecting integer overflow and underflow in arithmetic expressions compared to PVS, but still misses a number of seeded errors.

#### Divide by zero
{:.no_toc}
Both PVS-Studio and cppcheck do a good job of catching potential divide-by-zero errors, with cppcheck having a slight edge. 

### Dead code
{:.no_toc}
PVS-Studio tends to do a somewhat better job than cppcheck at detecting various types of dead code, such as `for` loops and `if` statements where the condition will never be true.

PVS-Studio also very helpfully flags any unconditional `break` statements in a loop -- these are almost always going to be a mistake.

### Concurrency
{:.no_toc}
As mentioned above, neither tool detects *any* of the concurrency-related errors seeded in the ITC code.  Again, I regard that as a reasonable design choice, given the relatively small percentage of such errors that can be detected at compile-time.

### Memory Errors
{:.no_toc}
As discussed earlier, not all memory errors can be detected at compile-time, so the lack of any error output certainly doesn't mean that the code doesn't have memory errors -- it just means that they can't be detected by the tools. But while many memory errors cannot be detected at compile-time, for those that can be, detecting them is a big win.

#### Double free
{:.no_toc}
cppcheck does an excellent job of detecting double-free errors (11 out of 12), while PVS-Studio only flags one of the seeded errors.

#### Free-ing non-allocated memory
{:.no_toc}
On the other hand, PVS-Studio does a better job of detecting attempts to free memory that was not allocated dynamically (e.g., local variables).  

#### Freeing a NULL pointer
{:.no_toc}
Neither tool does a particularly good job of catching these.  Perhaps that is because freeing a NULL pointer is actually not an error, but doing so is certainly a clue that the code may have other problems.

#### Dangling pointers
{:.no_toc}
cppcheck does a somewhat better job of detecting the use of dangling pointers (where the pointed-to object has already been freed).

#### Allocation failures
{:.no_toc}
If you're writing code for an embedded system, then checking for and handling allocation failures can be important, because your application is likely written to expect them, and do something about them.  But more commonly, running out of memory simply means that you're screwed, and attempting to deal with the problem is unlikely to make things better.

Neither tool detects code that doesn't handle allocation failures, but cppcheck does flag some allocation-related problems (as leaks, which is not correct, but it is a clue that there is a problem lurking).

#### Memory Leaks
{:.no_toc}
Typically, memory leaks are only evident at run-time, but there are some cases where they can be detected at compile-time, and in those cases cppcheck does a pretty good job. 

#### Null pointer
{:.no_toc}
Both PVS-Studio and cppcheck do a good job of flagging code that dereferences a NULL pointer, although neither tool catches all the errors in the benchmark code.

#### Returning a pointer to a local variable
{:.no_toc}
Both PVS-Studio and cppcheck detect returning a pointer to a local variable that is allocated on the stack.

#### Accessing un-initialized memory
{:.no_toc}
PVS-Studio does a somewhat better job than cppcheck of flagging accesses to uninitialized memory.

### Infinite loops
{:.no_toc}
Both cppcheck and PVS-Studio detect some infinite loop errors, but miss several others.  It could be that this is by design, since the code that is not flagged tends to resemble some idioms (e.g., ` while (true)`) that are often used deliberately.  

### Ignored return values
{:.no_toc}
PVS-Studio is quite clever here -- it will complain about an unused return value from a function, *if* it can determine that the function has no side effects.  It also knows about some common STL functions that do not have side effects, and will warn if their return values are ignored.

cppcheck doesn't check for return values per se, but it will detect an assignment that is never referenced.  This makes some sense, since warning on ignored return values could result in a large number of false positives.

### Empty/short blocks
{:.no_toc}
Both tools detect certain cases of empty blocks (e.g., `if (...);` -- note the trailing semi-colon).  

What neither tool does is warn about "short" blocks -- where a conditional block is not enclosed in braces, and so it's not 100% clear whether the conditional is meant to cover more than one statement:


    if (...)
       statement1();
       statement2();

If you've adopted a convention that even single-statement blocks need to be enclosed in braces, then this situation may not pertain (and good for you!).  Still, I think this would be a worthwhile addition -- at least in the "style" category.

### Dead stores
{:.no_toc}
cppcheck does a particularly good job of detecting dead stores (where an assignment is never subsequently used).  PVS-Studio, on the other hand, flags two or more consecutive assignments to a variable, without an intervening reference.  PVS-Studio will also flag assignment of a variable to itself (which is unlikely to be what was intended).
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Custom-Tailored Configuration]]></title>
    <link href="http://btorpey.github.io/blog/2016/10/13/custom-tailor/"/>
    <updated>2016-10-13T00:00:00-04:00</updated>
    <id>http://btorpey.github.io/blog/2016/10/13/custom-tailor</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/customtailor.jpg">

As developers, we seem to take a special delight in personalizing the virtual worlds in which we work -- from color palettes to keyboards, fonts, macros, you name it.  "Off-the-rack" is never good enough, we want Saville Row tailoring for our environments.

And a lot of the tools we use support and encourage that customization, giving us control over every little option.

But not every tool we use does so -- read on to learn a very simple trick to how to take control even when your tool doesn't make that easy.

<!-- more -->

In Linux, we have a couple of common ways to customize the way our tools work -- by defining environment variables, and by using configuration files.  Sometimes these two mechanisms work well together, and we can include environment variables in configuration files to make them flexible in different situations.

Not every tool can expand environment varaiables in its configuration files, however.  In that case, you can use this simple Perl one-liner to subsitute values from the environment into any plain-text file.

    perl -pe '$_=qx"/bin/echo -n \"$_\"";' < sample.ini


What's happpening here is

The `-p` switch tells Perl to read every line of input and print it.

The `-e` switch tells Perl to execute the supplied Perl code against every line of input.

The code snippet replaces the value of the input line (`$_`) with the results of the shell command specified by the `qx` function.  That shell command simply echos[^echo] the value of the line (`$_`), but it does so inside double quotes (the `\"`), which causes the shell to replace any environment variable with its value.

[^echo]: Note that we use /bin/echo here, instead of just plain echo, to get around an issue with the echo command in BSD (i.e., OSX).

And that's it!  Since the subsitution is being done by the shell itself, you can use either form for the environment variable (either `$VARIABLE` or `${VARIABLE}`), and the replacement is always done using the rules for the current shell.

Here's an example -- let's create a simple .ini type file, like so:

    username=$USER
    host=$HOSTNAME
    home-directory=$HOME
    current-directory=$PWD

When we run this file through our Perl one-liner, we get:

    perl -pe '$_=qx"/bin/echo -n \"$_\"";' < sample.ini
    username=btorpey
    host=btmac
    home-directory=/Users/btorpey
    current-directory=/Users/btorpey/blog/code/tailor

One thing to watch out for is that things can get a little hinky if your input file contains quotes, since the shell will interpret those, and probably not in the way you intend.  At least in my experience, that would be pretty rare -- but if you do get peculiar output that would be something to check.
</p>
]]></content>
  </entry>
  
</feed>
