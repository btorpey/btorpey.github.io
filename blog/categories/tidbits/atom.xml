<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: tidbits | Confessions of a Wall Street Programmer]]></title>
  <link href="http://btorpey.github.io/blog/categories/tidbits/atom.xml" rel="self"/>
  <link href="http://btorpey.github.io/"/>
  <updated>2017-05-11T21:15:36-04:00</updated>
  <id>http://btorpey.github.io/</id>
  <author>
    <name><![CDATA[Bill Torpey]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[We Don't Need No Stinkin' Databases]]></title>
    <link href="http://btorpey.github.io/blog/2017/05/10/join/"/>
    <updated>2017-05-10T00:00:00-04:00</updated>
    <id>http://btorpey.github.io/blog/2017/05/10/join</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/Gold_Hat_portrayed_by_Alfonso_Bedoya.jpg" width="220" height="162">

I've been working on performance analysis recently, and a large part of that is scraping log files to capture interesting events and chart them.

I'm continually surprised by the things that you can do using plain old bash and his friends, but this latest one took the cake for me.

<!-- more -->

Did you know that Linux includes a utility named `join`?  Me neither.  Can you guess what it does?  Yup, that's right -- it does the equivalent of a database join across plain text files.

Let me clarify that with a real-world example -- one of the datasets I've been analyzing counts the number of messages sent and received in a format roughly like this:

|Timestamp| Recv |
|:--------|-----:|
| HH:MM:SS| x |

<br>
Complicating matters is that sent and received messages are parsed out separately, so we also have a separate file that looks like this:

|Timestamp| Send |
|:--------|-----:|
| HH:MM:SS| y |

<br>
But what we really want is something like this:

|Timestamp| Recv | Send |
|:--------|-----:|------:|
| HH:MM:SS| x | y |

<br>
I had stumbled across the `join` command and thought it would be a good way to combine the two files.

Here are snips from the two files:

    $ cat recv.txt
    Timestamp	Recv
    2016/10/25-16:04:58	7
    2016/10/25-16:04:59	1
    2016/10/25-16:05:00	7
    2016/10/25-16:05:01	9
    2016/10/25-16:05:28	3
    2016/10/25-16:05:31	9
    2016/10/25-16:05:58	3
    2016/10/25-16:06:01	9
    2016/10/25-16:06:28	3
<br>

    $ cat send.txt
    Timestamp	Send
    2016/10/25-16:04:58	6
    2016/10/25-16:05:01	18
    2016/10/25-16:05:28	3
    2016/10/25-16:05:31	9
    2016/10/25-16:05:58	3
    2016/10/25-16:06:01	9
    2016/10/25-16:06:28	3
    2016/10/25-16:06:31	9
    2016/10/25-16:06:58	3


Doing a simple join with no parameters gives this:

    $ join recv.txt send.txt
    Timestamp Recv Send
    2016/10/25-16:04:58 7 6
    2016/10/25-16:05:01 9 18
    2016/10/25-16:05:28 3 3
    2016/10/25-16:05:31 9 9
    2016/10/25-16:05:58 3 3
    2016/10/25-16:06:01 9 9
    2016/10/25-16:06:28 3 3

As you can see, we're missing some of the measurements.  This is because by default `join` does an [inner join](https://en.wikipedia.org/wiki/Join_(SQL)#Inner_join) of the two files (the intersection, in set theory).

That's OK, but not really what we want.  We really need to be able to reflect each value from both datasets, and for that we need an [outer join](https://en.wikipedia.org/wiki/Join_(SQL)#Outer_join), or union.

It turns out that `join` can do that too, although the syntax is a bit more complicated:

    $ join -t $'\t' -o 0,1.2,2.2 -a 1 -a 2 recv.txt send.txt
    Timestamp	Recv	Send
    2016/10/25-16:04:58	7	6
    2016/10/25-16:04:59	1
    2016/10/25-16:05:00	7
    2016/10/25-16:05:01	9	18
    2016/10/25-16:05:28	3	3
    2016/10/25-16:05:31	9	9
    2016/10/25-16:05:58	3	3
    2016/10/25-16:06:01	9	9
    2016/10/25-16:06:28	3	3
    2016/10/25-16:06:31		9
    2016/10/25-16:06:58		3


A brief run-down of the parameters is probably in order:

|Parameter | Description
|----------|------------
| `-t $'\t'` | The `-t` parameter tells `join` what to use as the separator between fields.  The tab character is the best choice, as most Unix utilities assume that by default, and both Excel and Numbers can work with tab-delimited files.<br>The leading dollar-sign is a [trick](https://unix.stackexchange.com/a/46931/198530) used to to pass a literal tab character on the command line  .
| `-o&nbsp;0,1.2,2.2` | Specifies which fields to output.  In this case, we want the "join field" (in this case, the first field from both files), then the second field from file #1, then the second field from file #2.
| `-a 1` | Tells `join` that we want **all** the fields from file #1.
| `-a 2` | Ditto for file #2.

As you can probably see, you can also get fancy and do things like left outer joins and right outer joins, depending on the parameters passed.

Of course, you could easily import these text files into a "real" database and generate reports that way.  But, you can accomplish a surprising amount of data manipulation and reporting with Linux's built-in utilities and plain old text files.
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Custom-Tailored Configuration]]></title>
    <link href="http://btorpey.github.io/blog/2016/10/13/custom-tailor/"/>
    <updated>2016-10-13T00:00:00-04:00</updated>
    <id>http://btorpey.github.io/blog/2016/10/13/custom-tailor</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/customtailor.jpg">

As developers, we seem to take a special delight in personalizing the virtual worlds in which we work -- from color palettes to keyboards, fonts, macros, you name it.  "Off-the-rack" is never good enough, we want Saville Row tailoring for our environments.

And a lot of the tools we use support and encourage that customization, giving us control over every little option.

But not every tool we use does so -- read on to learn a very simple trick to how to take control even when your tool doesn't make that easy.

<!-- more -->

In Linux, we have a couple of common ways to customize the way our tools work -- by defining environment variables, and by using configuration files.  Sometimes these two mechanisms work well together, and we can include environment variables in configuration files to make them flexible in different situations.

Not every tool can expand environment varaiables in its configuration files, however.  In that case, you can use this simple Perl one-liner to subsitute values from the environment into any plain-text file.

    perl -pe '$_=qx"/bin/echo -n \"$_\"";' < sample.ini


What's happpening here is

The `-p` switch tells Perl to read every line of input and print it.

The `-e` switch tells Perl to execute the supplied Perl code against every line of input.

The code snippet replaces the value of the input line (`$_`) with the results of the shell command specified by the `qx` function.  That shell command simply echos[^echo] the value of the line (`$_`), but it does so inside double quotes (the `\"`), which causes the shell to replace any environment variable with its value.

[^echo]: Note that we use /bin/echo here, instead of just plain echo, to get around an issue with the echo command in BSD (i.e., OSX).

And that's it!  Since the subsitution is being done by the shell itself, you can use either form for the environment variable (either `$VARIABLE` or `${VARIABLE}`), and the replacement is always done using the rules for the current shell.

Here's an example -- let's create a simple .ini type file, like so:

    username=$USER
    host=$HOSTNAME
    home-directory=$HOME
    current-directory=$PWD

When we run this file through our Perl one-liner, we get:

    perl -pe '$_=qx"/bin/echo -n \"$_\"";' < sample.ini
    username=btorpey
    host=btmac
    home-directory=/Users/btorpey
    current-directory=/Users/btorpey/blog/code/tailor

One thing to watch out for is that things can get a little hinky if your input file contains quotes, since the shell will interpret those, and probably not in the way you intend.  At least in my experience, that would be pretty rare -- but if you do get peculiar output that would be something to check.
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Remote Scripting with bash and ssh]]></title>
    <link href="http://btorpey.github.io/blog/2015/10/13/remote-scripting-with-bash-and-ssh/"/>
    <updated>2015-10-13T00:00:00-04:00</updated>
    <id>http://btorpey.github.io/blog/2015/10/13/remote-scripting-with-bash-and-ssh</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/multimonitors.jpg" width="370" height="245">

Nowadays it's pretty common for applications to be distributed across multiple
machines, which can be good for scalability and resilience.

But it does mean that we have more machines to monitor -- sometimes a LOT more!

Read on for a handy tip that will let you do a lot of those tasks from any old
session (and maybe lose some of those screens)!

<!-- more -->

For really simple tasks, remote shell access using ssh is fine.  But oftentimes
the tasks we need to perform on these systems are complicated enough that they
really should be scripted.

And especially when under pressure, (e.g.,  troubleshooting a problem in a
production system) it's good for these tasks to be automated. For one thing,
that means they can be tested ahead of time, so you don't end up doing the
dreaded `rm -rf *` by mistake.  (Don't laugh -- I've actually seen that happen).

Now, I've seen people do this by copying scripts to a known location on the
remote machines so they can be executed.  That works, but has some
disadvantages: it clutters up the remote system(s), and it creates one more
artifact that needs to be distributed and managed (e.g., updated when it
changes).

If you've got a bunch of related scripts, then you're going to have to bite the
bullet and manage them (perhaps with something like Puppet).

But for simple tasks, the following trick can come in very handy:

`
ssh HOST ‘bash –s ‘ < local_script.sh
`

What we're doing here is running bash remotely and telling bash to get its input
from stdin.  We're also redirecting local_script.sh to the stdin of ssh, which
is what the remote bash will end up reading.

As long as local_script.sh is completely self-contained, this works like a
charm.

For instance, to login to a remote machine and see if hyper-threading is enabled
on that machine:

`
ssh HOST 'bash -s' < ht.sh
`

Where ht.sh looks like this:

<div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span> (ht.sh)</span> <a href='/downloads/code/bash/ht.sh'>download</a></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c">#!/bin/bash</span>
</span><span class='line'>
</span><span class='line'><span class="c"># cribbed from http://unix.stackexchange.com/questions/33450/checking-if-hyperthreading-is-enabled-or-not</span>
</span><span class='line'><span class="c">#</span>
</span><span class='line'><span class="c"># NOTE:  There does not seem to be a good way to determine if HT is available but not enabled on a particular machine:</span>
</span><span class='line'><span class="c"># - &#39;ht&#39; flag in /proc/cpuinfo is unreliable</span>
</span><span class='line'><span class="c"># - lscpu could be used, but is not part of RH5</span>
</span><span class='line'><span class="c"># - dmidecode could be used, but requires root permissions</span>
</span><span class='line'><span class="c">#</span>
</span><span class='line'><span class="c"># So for now we just report whether HT is enabled or not</span>
</span><span class='line'>
</span><span class='line'><span class="nb">echo</span> -n <span class="k">${</span><span class="nv">HOSTNAME</span><span class="k">}</span>
</span><span class='line'>
</span><span class='line'><span class="nv">nproc</span><span class="o">=</span><span class="k">$(</span>grep -i <span class="s2">&quot;processor&quot;</span> /proc/cpuinfo | sort -u | wc -l<span class="k">)</span>
</span><span class='line'><span class="nv">phycore</span><span class="o">=</span><span class="k">$(</span>cat /proc/cpuinfo | egrep <span class="s2">&quot;core id|physical id&quot;</span> | tr -d <span class="s2">&quot;\n&quot;</span> | sed s/physical/<span class="se">\\</span>nphysical/g | grep -v ^<span class="nv">$ </span>| sort -u | wc -l<span class="k">)</span>
</span><span class='line'><span class="k">if</span> <span class="o">[</span> -z <span class="s2">&quot;$(echo &quot;</span><span class="nv">$phycore</span> *2<span class="s2">&quot; | bc | grep $nproc)&quot;</span> <span class="o">]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">   </span><span class="nb">echo</span> <span class="s2">&quot;: HT disabled&quot;</span>
</span><span class='line'><span class="k">else</span>
</span><span class='line'><span class="k">   </span><span class="nb">echo</span> <span class="s2">&quot;: HT enabled&quot;</span>
</span><span class='line'><span class="k">fi</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>


(The script above was cribbed from http://unix.stackexchange.com/a/33509 --
thanks, Nils!)


Of course, all the normal redirection rules apply -- you just have to keep in
mind that you're redirecting to ssh, which is then redirecting to bash on the
input side.  On the output side, it's reversed.

Give this a try the next time you need to do some quick tasks over ssh and
you'll be able to get rid of a few of those monitors!
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Repent, Sinner!]]></title>
    <link href="http://btorpey.github.io/blog/2014/09/21/repent/"/>
    <updated>2014-09-21T00:00:00-04:00</updated>
    <id>http://btorpey.github.io/blog/2014/09/21/repent</id>
    <content type="html"><![CDATA[<p><img class="left" src="/images/nun-with-ruler.jpg" width="240" height="160"> 

When I was a kid I went to Catholic school, and back in those days 
the nuns would indeed rap your knuckles with a ruler if you
misbehaved. That doesn't happen so much any more, but when I see someone 
making use of the [copy-paste anti-pattern](http://c2.com/cgi/wiki?CopyAndPasteProgramming), 
I'm tempted to reach for a ruler myself. 
(I know, probably not a good career move ;-)

Short of rapping someone's knuckles with a ruler, though, how do you show some poor sinner the error of his ways?

<!--more-->

Enter [CPD, or copy-paste detector](http://pmd.sourceforge.net/pmd-5.1.3/cpd-usage.html). 
This does pretty much what you would guess from its name -- it
spins through all the code you give it, and analyzes it for repeated sequences.
[^1]

Here's an example of running the GUI version against the code I used 
in an [earlier post](http://btorpey.github.io/blog/2014/02/12/shared-singletons/) on smart pointers.

<img class="right" src="/images/cpd.png">

(Note that the "Ignore literals" and "Ignore identifiers" checkboxes are
disabled if you select C++ as the language - these options [are only implemented for Java currently](http://sourceforge.net/p/pmd/discussion/188193/thread/91553283)).

The site has several more examples, but [this one](http://pmd.sourceforge.net/pmd-5.1.3/cpdresults.txt) just blew my mind -- 
hard to imagine how anyone could write this code in
the first place, much less be so confident that it is correct that they just
copy and paste it in two different files (with nary a comment to tie the two
together)?

<pre>
=====================================================================
Found a 19 line (329 tokens) duplication in the following files: 
Starting at line 685 of /usr/local/java/src/java/util/BitSet.java
Starting at line 2270 of /usr/local/java/src/java/math/BigInteger.java
    static int bitLen(int w) {
        // Binary search - decision tree (5 tests, rarely 6)
        return
         (w < 1<<15 ?
          (w < 1<<7 ?
           (w < 1<<3 ?
            (w < 1<<1 ? (w < 1<<0 ? (w<0 ? 32 : 0) : 1) : (w < 1<<2 ? 2 : 3)) :
            (w < 1<<5 ? (w < 1<<4 ? 4 : 5) : (w < 1<<6 ? 6 : 7))) :
           (w < 1<<11 ?
            (w < 1<<9 ? (w < 1<<8 ? 8 : 9) : (w < 1<<10 ? 10 : 11)) :
            (w < 1<<13 ? (w < 1<<12 ? 12 : 13) : (w < 1<<14 ? 14 : 15)))) :
          (w < 1<<23 ?
           (w < 1<<19 ?
            (w < 1<<17 ? (w < 1<<16 ? 16 : 17) : (w < 1<<18 ? 18 : 19)) :
            (w < 1<<21 ? (w < 1<<20 ? 20 : 21) : (w < 1<<22 ? 22 : 23))) :
           (w < 1<<27 ?
            (w < 1<<25 ? (w < 1<<24 ? 24 : 25) : (w < 1<<26 ? 26 : 27)) :
            (w < 1<<29 ? (w < 1<<28 ? 28 : 29) : (w < 1<<30 ? 30 : 31)))));
    }

</pre>

So, if you need to lead someone to the light, try PMD's copy-paste detector.  It
may hurt a bit, but a lot less than a sharp rap on the knuckles!

One last caveat about CPD: it does not like symlinks at all -- you must give it the real path names for any source files, or
you will just get a bunch of "Skipping ... since it appears to be a symlink" messages.


[^1]: CPD is part of the [PMD tool](http://pmd.sourceforge.net/pmd-5.1.3/), which can do a lot of useful things with Java code. But since I'm primarily dealing with C++ code these days (and because duplicate code is such a hot-button issue for me), CPD is the part that I use.
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Guess What Day It Is!]]></title>
    <link href="http://btorpey.github.io/blog/2014/07/23/perl-stdin/"/>
    <updated>2014-07-23T00:00:00-04:00</updated>
    <id>http://btorpey.github.io/blog/2014/07/23/perl-stdin</id>
    <content type="html"><![CDATA[<p><img class="left" src="/images/phl.pm.org-camel.png" width="320" height="240"> 

No, not that -- it's Perl day.  (Well, actually it's just Wednesday, but you get the idea).

Sometimes it seems that everybody likes to hate on Perl, but I think their
animus is misdirected. It's not Perl that's the problem, it's those \^\\\$\(\.\#\!\)?$
regular expressions.

Or, as Jamie Zawinski once said 
["Some people, when confronted with a problem, think "I know, I'll use regular expressions." Now they have two problems."](http://en.wikiquote.org/wiki/Jamie_Zawinski).

Well, I'm here to tell you that it's possible to write whole Perl programs that
actually accomplish useful work, **without any regular expressions at all**! And, if you do
that, you can actually *read the code!*

It turns out that Perl is a dandy scripting language, and while some may take issue
with its flexibility ("There's more than one way to do it"), others (including me) find that flexibility very useful.

<!--more-->

One example of that flexibility is how easy it is to create a Perl program that
can read input either from stdin, or from a file specified on the command line.

    local *INFILE;
    if (defined($ARGV[0])) {
        open(INFILE, "<:crlf", "$ARGV[0]") or die "Cant open $ARGV[0]\n";
    }
    else {
        *INFILE = *STDIN;
    }

    while (<INFILE>) {
    }

    close(INFILE);

The above snippet does just that, and also works well with command-line parsers
(e.g., `GetOpt`) that eat their parameters by removing them from the ARGV
array.


</p>
]]></content>
  </entry>
  
</feed>
